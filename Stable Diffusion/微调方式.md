## Extra networks

| Extra network     | Directory            | File types                        | How to use in prompt             |
| ----------------- | -------------------- | --------------------------------- | -------------------------------- |
| Textual Inversion | embeddings           | `*.pt`,`.bin` images              | embedding's filename             |
| Lora              | models/Lora          | `*.pt`                            | `<lora:filename:multiplier>`     |
| Hypernetworks     | models/hypernetworks | `*.pt`，`*.ckpt`，`*.safetensors` | `<hypernet:filename:multiplier>` |

### Textual Inversion

A method to fine tune weights for a token in CLIP.

they work well with the model you used during training. and not so well on different models

- [参考链接](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Textual-Inversion)
- [扩展](https://github.com/tkalayci71/embedding-inspector)

### Lora

A method to fine tune weights for CLIP and Unet, the language model and the actual image de-noiser used by Stable Diffusion.

Lora is added to the prompt by putting the following text into any location: `<lora:filename:multiplier>`, where filename is the name of file with Lora on disk, excluding extension, and multiplier is a number, generally from 0 to 1, that lets you choose how strongly Lora will affect the output. Lora cannot be added to the negative prompt.

The text for adding Lora to the prompt, `<lora:filename:multiplier>`, is only used to enable Lora, and is erased from prompt afterwards, so you can't do tricks with prompt editing like `[<lora:one:1.0>|<lora:two:1.0>]`. A batch with multiple different prompts will only use the Lora from the first prompt.

- [参考资料](https://github.com/kohya-ss/sd-scripts)
- [参考资料](https://rentry.org/2chAI_LoRA_Dreambooth_guide_english)
- [参考资料](https://github.com/opparco/stable-diffusion-webui-composable-lora)

### Hypernetworks

A method to fine tune weights for CLIP and Unet, the language model and the actual image de-noiser used by Stable Diffusion, generously donated to the world by our friends at Novel AI in autumn 2022. Works in the same way as Lora except for sharing weights for some layers. Multiplier can be used to choose how strongly the hypernetwork will affect the output.

- [参考资料](https://rentry.org/hypernetwork4dumdums)
- [扩展](https://github.com/aria1th/Hypernetwork-MonkeyPatch-Extension)
- [扩展](https://github.com/antis0007/sd-webui-multiple-hypernetworks)

### img2img alternative test

- Use a brief description of the scene: "A smiling woman with brown hair." Describing features you want to change helps. Set this as your starting prompt, and 'Original Input Prompt' in the script settings.
- You MUST use the Euler sampling method, as this script is built on it.
- Sampling steps: 50-60. This MUCH match the decode steps value in the script, or you'll have a bad time. Use 50 for this demo.
- CFG scale: 2 or lower. For this demo, use 1.8. (Hint, you can edit ui-config.json to change "img2img/CFG Scale/step" to .1 instead of .5.
- Denoising strength - this does matter, contrary to what the old docs said. Set it to 1.
- Width/Height - Use the width/height of the input image.
- Seed...you can ignore this. The reverse Euler is generating the noise for the image now.
- Decode cfg scale - Somewhere lower than 1 is the sweet spot. For the demo, use 1.
- Decode steps - as mentioned above, this should match your sampling steps. 50 for the demo, consider increasing to 60 for more detailed images.
